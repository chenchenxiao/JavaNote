    
    rdeis数据库的每个键值对都是由对象组成，键始终是字符串对象，值可以是5种数据类型
    redis中值是一个readObject，type表示对象类型，encoding表示编码类型，ptr指向数据结构，refcount引用计数，lru表示最后一次访问对象的时间戳
    
    底层数据结构
    
        字符串
            redis的字符串类型底层是通过c语言实现的，是通过SDS即简单动态字符串，与c字符串不同
           * sds结构有三个属性，len：表示sds所保存的字符串长度；buf[]：字节数组，用于保存字符串；free：记录buf数组中未使用字节的数量
            buf数组的最后会以空字符结尾，不过空间不计入len属性，是为了可以重用c语言的库函数
            与c字符串的区别：
                常数复杂度获取字符串长度：c字符串不记录自身的长度，要求长度必须遍历整个字符串，直到遍历空字符为止，复杂度为O(N)
                                         而sds在len属性中记录的字符串的长度，所以获取一个sds长度的复杂度为O(1)
                杜绝缓冲区溢出：c字符串不记录自身长度带来的另一个问题是容易造成缓冲区溢出，加入s1字符串要将s2字符串添加到尾部，此时是假定已经为s1分配了足够的空间，
                                但实际并没有，就会造成s1的数据被溢出到s2，导致s2保存到内容被修改。
                                与c字符串不同，sds在需要修改sds时，会先检查sds的空间是否满足修改所需的要求；如果不满足的话，API会自动将sds的空间扩展至执行修改所需的大小，然后才执行修改操作。            
                减少修改字符串时带来的内存重分配次数：c字符串的底层实现总是一个N+1个字符长的数组。因为C字符串的长度和底层数组的长度之间存在着这种关联性，所以每次修改字符串都要进行一个内存重分配操作。
                                                      而sds通过未使用空间接触了字符串和底层数组长度间的关联。使用了空间预分配和惰性空间释放两种优化策略
                                                      1.空间预分配
                                                        如果对sds进行修改后，sds的长度将小于1mb，那么程序分配free和len同等大小的未使用空间
                                                        如果修改后，sds的长度大于等于1mb，程序会分配给free1mb的未使用空间
                                                        通过这种策略，redis可以减少连续执行字符串操作所需的内存重分配次数，n次修改最多分配n次
                                                      2.惰性空间释放
                                                        用于优化sds的字符串缩短操作，当sds的API需要缩短sds保存到字符串时，程序并不立即使用内存重分配来回收缩短后多出来的字节，而是使用free属性将这些字节的数量记录起来，并等将来使用
                二进制安全：c字符串不能包含空字符，否则会被误认为是字符串结尾，这使得c字符串只能保存文本数据，而sds的api都是二进制安全的，所以sds的api都会以处理二进制的方式来处理sds存放在buf数组里的数据，sds使用len的值而不是空字符来判断字符串是否结束
                兼容部分c字符串函数，sds保留空字符结尾是为了让那些保存文本数据的sds可以重用一部分c字符串定义的函数
                
        链表
            是用c语言自己实现的一种数据结构
            一个listNode包含了pre前置节点，next后继节点，value节点值，用一个list来包含多个listNode
            在后续版本中listNode多了一个压缩列表指针ziplist，用来存放值，count表示压缩列表中元素的个数
            list包含了表头节点head，表尾节点tail，len链表节点数，node压缩列表节点的总数，节点值复制函数dup，节点值释放函数free，节点值对比函数metch
            特性：
                双端：链表节点有pre和next指针，获取前置和后置节点的复杂度都是O(1)
                无环：表头节点的prev指针和表尾节点的next指针都指向NULL
                带表头指针和表尾指针
                带链表长度计数器
                多态：链表节点用void*指针来保存节点值，可以用来保存不同类型的值
        
        字典
            也是用c语言自己实现的一种数据结构
            用dict来表示字典，由一个type属性和privdata，是针对不同类型的键值对，为创建多态字典而设置的；ht属性表示两个哈希表；trehashidx表示是否正在进行rehash，不是为-1
            dictht表示哈希表，table数组表示哈希表节点数组；size哈希表大小，sizemask哈希表大小掩码，用于计算索引值，总是size-1，used表示已有节点的数量
            dictEntry表示哈希表节点，key表示键，v表示值，可以是指针类型，int类型，uint类型；next表示下个哈希表节点，形成链表
            查找时先通过hash算法计算得到key的哈希值，再根据哈希值得出对应的索引值，链表的插入使用头插法
            rehash是扩展和收缩哈希表的操作：会先为字典的ht[1]哈希表分配空间，大小：如果执行的是扩展操作，大小为大于两倍第一个哈希表节点数的2次幂；如果是收缩操作，大小为第一个哈希表数的2次幂
                                            将保存在ht[0]中的所有键值rehash到ht[1]上，rehash会重新计算键的哈希值和索引值
                                            当所有键值都迁移到ht[1]后，释放ht[0]，将ht[1]1设置为ht[0]，并在ht[1]新建一个空白哈希表，为下一个次rehash做准备
                                            rehash操作是渐进式的，在字典中维持一个索引计数变量rehashidx，初始为0，每次对字典进行操作时，会顺带将ht[0]在rehashidx索引上的所有键值对rehash到[1]，当完成后，rehashidx值加一
                                            缩容是当哈希表元素的个数小于数组长度的10%才发生                                 
                                            
        跳表：是有序集合的底层实现
            zskiplistNode表示跳表节点，zskiplistLevel表示层，里面一个前进指针和跨度，前进指针用于从表头向表尾方向访问节点，跨度用于记录两个节点间的距离；backword后退指针用于从表尾向表头访问，score分值是一个double浮点数，跳表中的节点按分值顺序排序，，obj成员对象是一个指针，指向一个字符串对象，保存一个sds值
            obj成员对象必须是唯一的，分值可以相同，相同的分值按成员对象在字典序中的大小顺序排序       
            zskiplist持有zskiplistNode;header和tail分别表示表头结点和表尾节点，length表示节点数，level表示层数中最大的节点的层数                            
            
        整数集合：是集合键的底层实现之一
            用于保存整数值的集合抽象数据结构，可以保存16，32，64位的整数值，保证集合中不会出现重复元素
            intset表示一个整数集合：encoding表示编码方式，length表示元素数量，contents保存元素的数组
            当向一个整数集合添加一个类型更长的元素时，整数集合会进行升级：根据新元素的类型扩展数组空间大小并未新元素分配空间；将数组中的元素转换成新元素的类型并放到正确的位置上，将新元素添加到数组中。
            升级的好处：提升灵活性；节约内存空间
                                        
        压缩列表：是一种为节约内存而开发的顺序型数据结构
            因为压缩列表的结构是紧凑的，没有冗余空间，所以每次添加元素都要扩展内存，这取决于当前的列表内存大小和内存分配器算法，可能重新分配内存空间，并拷贝数据，也可能在原有地址上扩展
            被用作列表键和哈希键的底层实现之一，可以包含多个节点，每个节点可以保存一个字节数组或者整数值；添加新节点或者删除节点可能会引发连锁的更新操作。
            zlbytes用于记录整个压缩列表占用的内存字节数，zltail记录压缩列表表尾几点距离列表的起始地址有多少字节，通过这个无须遍历整个压缩列表就可以确地表尾节点的地址
            zlen记录了压缩列表包含的节点数量，entryX压缩列表的节点，zlend用于标记压缩列表的末端
           listpack
    
    对象
        字符串对象
            字符串对象的编码可以是int，raw或embstr，如果一个保存的是整数值并且可以用long类型来表示，则会将编码设置为int
            如果字符串的长度小于等于32字节，会用embstr编码的方式来保存这个字符串值，该编码是用于保存短字符串对象的，
            当对embstr编码的字符串对象进行修改时，会将编码改为raw，因为embstr是只读的
        
        列表对象
            列表对象的编码可以是ziplist或者linkedlist
            如果用linkedlist编码来保存对象，每个链表节点都保存了一个字符串对象，而每个字符串对象都保存了一个元素
            编码转换：以下情况使用ziplist
                列表对象保存的所有字符串元素的长度都小于64字节
                列表对象保存的元素数量小于512个
        
        哈希对象
            哈希对象的编码可以是ziplist或hashtable
            ziplist编码的哈希对象每当有新的键值对要加入到哈希对象时，会先将保存了键的压缩列表节点推入到压缩列表尾部，再把保存了值的节点推入尾部，键在前，值在后
            编码转换：以下使用ziplist
                哈希对象保存的所有键值对的键和值的字符串长度都小于64字节
                哈希对象保存到键值对数小于512
            
        集合对象
            集合对象的编码可以是intset或者hashtable
            inset编码使用整数集合来保存元素，hashtable编码使用字典，字典的每个键都是一个字符串对象，每个字符串对象都是一个集合元素，而字典的值则全部被设置为NULL
            编码的转换：以下使用intset
                集合对象保存的所有元素都是整数值
                集合对象保存的元素数量不超过512个
                
        有序集合对象
            有序集合的编码可以是ziplist或者skiplist
            ziplist编码时，每个集合元素使用两个紧挨在一起的压缩列表元素节点来保存，第一个节点保存元素的成员，第二个保存元素的分值，按分值顺序排列
            使用skiplist时，是使用zset结构作为底层实现，一个在set包含一个字典和一个跳表
            zset中的跳表按分值从小到大保存了所有集合元素，每个跳表节点保存了一个元素，object属性保存了元素的成员，而score则保存了分值，可以通过跳表进行范围操作
            zset中的字典为有序集合创建了一个从成员到分值的映射，通过字典可以用O(1)复杂度查找指点成员的分值
            zset的跳表和字典会通过指针来共享相同元素的成员和分值，不会浪费额外的内存
            编码的转换：以下使用ziplist
                有序集合保存的元素数量小于128
                有序集合保存的所有元素成员的长度都小于64字节
                
        内存回收
            redis使用计数的方法来实现对对象的监控，初始为1，当对象被新程序使用时，值加一，不再被一个成效使用时，值减一，值为0时，对象所占用的内存会被释放        
        
    应用
        分布式锁：本质上要实现的目的就是在redis里占一个“坑”，当别的进行要来占时，发型已经有人蹲在那里，就只好放弃或等待
            在redis2.8后支持set指令扩展参数：set lock:lockName true ex time nx，是setnx和expire组合一起的原子指令，分布式锁的奥义所在
            超时问题：在加锁和解锁间的逻辑还没有执行完，其他线程就重新持有了这把锁，导致临界区代码不能得到严格执行
            可重入性：redis要支持锁可重入，要对set方法进行包装，java是通过一个泛型为Map<String,Integer>的ThreadLocal来实现的，每次获取锁就会取出锁然后对计数值加一，释放锁就会减一，直到计数值为0真正释放锁
        
        延时队列：当队列为空时通过延时的方式来避免浪费生命的空轮询
            通过blpop/brpop来实现延时，b是blocking的意思，也就是阻塞读，在队列没有数据的时候，会立即进入休眠状态，一旦数据来了，就立刻醒过来
            要注意空闲连接自动断开的问题，如果线程一直阻塞，客户端连接就成了闲置连接，过久的话服务器会主动断开连接，要注意捕获异常并且重试
            延时队列可以通过zset来实现，把消息序列化成一个字符串作为zset的value，消息的到期处理时间为score，多个线程（保障可用性）轮询zset获取到期的任务进行处理
            每次只取一条消息，如果取不到就等待一小会继续取，如果取到了就把拿到的消息反序列化，执行消息任务
            redis消息队列无法保证100%可靠性：若消费者挂了，此时多个消费者将任务存入到队列中，会很难找到
            
        HyperLogLog：高级数据结构    
            用来解决统计问题，提供不精确的去重技术方案，标准误差0.81%，有两个指令，pfadd和pfcount，还有一个pfmerge用于将多个pf计数值累加形成一个新的pf值
            要占12k的存储空间，不适合统计单个用户相关的信息，在数据量多的时候比起用set存储要节省很多空间
            在计数比较小时，采用稀疏矩阵存储，空间占用小，仅仅在计数慢慢变大，超过了阀值才会一次性变成稠密矩阵，才占用12k空间
            
        简单限流
            用一个zset结构记录用户的行为历史，每个行为都作为zset中的一个key保存下来，value用毫秒时间戳，同个用户同一种行为用一个zset记录。
            为节省内存，只需保留时间窗口内的行为记录，通过统计滑动窗口内的行为数量与阀值进行比较就可以得出当前的行为是否允许    
            
        漏斗限流
            漏洞的容量是有限的，如果漏嘴流水的速率大于灌水的速率，那么漏斗永远装不满，如果小于，那么灌水就要暂停并等待漏斗腾空 
            在redis4.0后提供了一个限流模块，叫redis-cell，使用了漏斗算法，并提供了原子的限流指令，只有一个cl.throttle指令  
            
        布隆过滤器：来去重的，比如爬虫去掉重复URL
            底层结构是一个大型位数组和几个无偏的hash函数
            当add元素时，先通过hash函数计算得到一个索引值，将这个值与数组长度取模得到在数组中的位置，不同的hash函数会得到不同的值
            将对应位置的值设为1，表示来过，要查询是否存在key时，通过hash得到索引，再得到对应数组位置时，如果有一个位置的值为0，那就一定不存在，否则也是不一定存在，因为有可能是其他key存放的
            数组越大，判断的正确率越高    
        
        GeoHash：redis地理位置排序使用的算法
            Geo指令添加时是添加多个经纬度名称的三元组，内部结构实际上只是一个zset，通过zset的score排序可以得到坐标附件的其他元素，通过score还原成坐标值就可以得到元素值的原始坐标
            可以获取集合元素的经纬度坐标，距离最近的元素，获取元素间的距离，获取元素经纬度的hash值
            如果使用Geo数据结构，会将数据都放入一个zset中，在集群环境下，集合可能从一个节点迁移到另一个节点，如果单个key数据过大，会造成影响，所以不建议集群环境使用Geo的数据
            
        Scan：查找满足特定正则字符串规则的key
            通过游标分步进行，不会阻塞线程，有limit参数，服务器无需保存游标状态，返回的结果可能重复，需要客户端去重，遍历结束的标志是游标值为零
            游标就是字典中节点数组的位置索引，称之为槽，limit表示需要遍历的槽位数，因为有些槽位可能为空，有些链表可能多个元素，所以返回的结果不一定按limit指定的
            要避免大key的产生。集群环境下，key太大会导致数据迁移卡顿，在内存分配上，大key会一次性申请更大的内存，导致卡顿，如果这个key被删除，内存一次性回收又会导致卡顿
        
    原理
        线程IO模型
            redis单线程为什么还能这么快？
                因为它所有的数据都在内存中，所有运算都是内存级别的运算。
            redis单线程如何处理多个并发的客户端连接？
                通过多路复用，事件轮询的机制
            最简单的事件轮询API是select，其他的还有kqueue和epoll，在没有事件进来的时候会等待指定的timeout时间，线程会阻塞，如果有事件会立即返回，如果时间过后没有事件也是会返回，然后线程处理相应事件，
            处理完后继续轮询，这样形成了一个事件循环，一个循环一个周期
            伪代码：
                read_events, write_events = select(read_fds, write_fds, timeout)
                for event in read_events:
                    handle_read(event.fd)
                for event in write_events:
                    handle_write(event.fd)
                handle_others()  # 处理其它事情，如定时任务等
            指令队列：redis会将每个客户端套接字都关联一个指令队列，客户端的指令通过队列来排队顺序处理，先到先服务
            响应队列：redis也会为每个客户端关联一个响应队列，redis服务器通过响应队列将指令的返回结果回复给客户端。
            定时任务：如果线程阻塞的时间过长，导致定时任务无法得到准时调度，redis如何解决？
                redis的定时任务会记录在一个最小堆中，在每个周期中，reids会将堆顶已经到点的任务进行处理，
                处理完毕后，将最近一次任务要等待的时间记录下来，这个就是下个周期要等待的timeout，因为能够确定在这个timeout里没有其他定时任务需要处理
                
                
        持久化
            rbd（快照）原理：使用COW(Copy On Wriite)机制来实现
                             redis会在持久化时调用fork函数产生一个子进程，父进程继续处理客户端请求，子进程负责持久化。
                             子进程在刚产生时数据段和代码段跟父进程是一样的，子进程不会修改内存数据结构，而父进程必须持续服务客户端请求，然后对内存数据结构进行修改。
                             这个时候使用操作系统的COW机制进行数据段的页面的分离，数据段是由很多操作系统的页面组合而成，当对其中一个页面进行修改时，会将被共享的页面复制一份分离出来，
                             对复制的页面进行修改，这个时候子进程对应的页面并没改变，会遍历数据进行序列化写磁盘了。
            AOF原理：AOF存放的redis服务器对内存进行修改的指令记录，在收到指令后，会进行校验，如果没问题，就将指令记录到AOF中，先执行指令才将日志存盘。
                     AOF需要重写，避免AOF的日志越来越长，重写时，是通过子进程产生一个新的AOF文件，把失效的命令都去除掉（已过期，已删除的key写命令不保留，多个key的写只保留最后一个）
                     完成后会把这个过程发生的增量日志追加到这个新的AOF文件，完成后替换旧的。
                     如果机器突然宕机，AOF的内容还没完成刷到磁盘，会造成日志缺失，解决方法是通过fsync函数将指定文件的内容强制从内核缓存刷到磁盘。
             
            混合持久化：先用rbd的方式进行持久化，然后再用AOF的方式把这期间的增量记录到AOF文件中，这样在redis重启时，可以先加载rbd内容，然后再重返AOF日志就可以了，重启效率大幅度提升。
            
            AOP重放速度快，但是能保证数据的安全，而RBD持久化速度快，但是可能会丢失数据，比如在rbd过程中突然崩了，数据就会丢失
            redis不适合做数据库，因为事物支持差，没有索引，没有呢外键，多条件查询时操作不方便，开发效率低。
            reids先执行指令再记录aof文件是因为有可能指令是错误的，或者是无效的，先执行的话就不会记录这些无用的指令
            
        管道：通过改变读写的顺序带来性能的巨大提升，将多次往返的IO时间缩短为一次
            客户端和服务端都有一个有操作系统内核为套接字分配的发送缓存和接收缓存。
            当进行write时，只要把写好的数据写到发送缓冲即可，客户端会将发送缓冲的内容发送到网卡，然后将数据送到服务器的网卡，服务器网卡再把数据放到接收缓冲
            当read时，就要等待对端将数据发送到接收缓冲，再从接收缓存中取数据，所以read会等待一个网络的来回开销
            所以写-写-读-读比写-读-写-读要快，因为前者只要等待一个网络的来回开销，然后所有响应信息就已经回送到接收缓冲了，而后者需要等待两个网络的来回开销
            write操作只负责将数据写到本地操作系统内核的发送缓冲就返回了，如果发送缓冲满了，需要等待缓冲空出空闲空间来，这就是写操作IO的真正耗时
            read操作只负责将数据从本地操作系统内核的接收缓冲中取出来就行了，如果缓冲是空的，那么就需要等待数据到来，这就是读操作IO的真正耗时
            
        事物：multi开始，exec执行，discard丢弃 
            redis的事务并不是原子性的，仅仅满足了事务的隔离性
            可以通过Watch机制来解决并发修改，watch会在事务开始前盯住一个或多个关键变量，当事物执行时，redis会检查关键变量自watch后是否被其他客户端修改了，如果是，exec会返回null表示失败，这个时候客户端一般会选择重试
            redis禁止在mutil和exec之间执行watch指令，必须在mutil之前就做，否则会出错
            redis的事务不支持回滚的原因：redis命令只会因为错误的语法的失败，这也就是说是由于编程错误的原因造成的，不应该出现在生产环境，而且回滚并不能解决编程带来的问题
        
        主从同步
            redis的主从数据是异步同步的，并不满足“一致性”的要求，但是满足“可用性”的要求，即使发生了主从网络断开，也可以正常对外提供修改服务。
            redis保证“最终一致性”， 从节点会努力追赶主节点，最终从节点的状态会和主节点的状态保持一致
            redis同步的是指令流，主节点会将那些对自己的状态产生修改性影响的指令记录在本地的内存buffer中，异步将buffer中的指令同步到从节点，
            从节点一边执行同步的指令流来达到和主节点一样的状态，一边向主节点反馈自己到哪里了（通过偏移量）
            buffer是一个环形数组，满了会覆盖前面的内容
            如果网络不好，短时间内无法进行同步，当网络恢复时buffer中的节点已经被覆盖了，这个时候就要用快照同步
            快照同步：在主库上将内存数据全部快照到磁盘文件中，然后将快照文件的内容全部传送到从节点，从节点接收完毕后，立即执行一次全量加载，加载前要把内存的数据清空，加载完后通知主节点进行增量同步。
                      在快照同步时，主节点的复制buffer还在不停的往前移动，如果同步的时间过长或者buffer过小，都会导致同步期间的增量指令在复制buffer中被覆盖，这样就无法进行增量复制，然后会再次发起快照同步，有可能陷入死循环。
            增加从节点时要进行一次快照同步，同步完继续进行增量同步。
            无盘复制：服务器直接通过套接字将快照内容发送到从节点，生成快照是一个遍历的过程，主节点会一边遍历内存，一边将序列号的内容发送到从节点，从节点跟之前一样。
            wait指令：让redis的复制从异步复制变为同步复制，确保系统的一致性。第一个参数表示多少个从库，第二个表示时间，如果为0，表示无限等待直到N个从库同步完成一致          
            
        
    扩展
        过期策略：redis所有的数据结构都可以设置过期时间，时间一到，就会自动删除。
                  redis会将每个设置了过期时间的key放入一个独立的字典，以后会定时遍历这个字典来删除到期的key。
                  定时扫描：redis采用了一种贪心策略，每次从过期字典随机20key，删除其中过期的key，如果过期的比率超过1/4，就重复这样做。为了避免循环过度，增加了时间的上线，默认不超过25ms。
                  redis中如果大量的key在同一时间过期了，会持续扫描过期字典直到字典中的key变得稀疏才会停止。会导致线上读写请求出现明显的卡顿现象，而且如果客户端请求到来时服务器刚好进入扫描状态，客户端请求超时了，那么大量的链接会因为超时关闭。
                  所以要注意过期时间，如果有大量的key过期，要给过期时间设置一个随机范围。
                
        LRU：当内存超过物理内存时需要用到
            近似的LRU算法，redis之所以不用LRU算法，是因为需要消耗大量的额外内存（LRU算法需要一个链表），redis的算法是采用随机采用法来淘汰元素
            当发现每次超过maxmemory时，会执行一次LRU淘汰算法，随机采样出5（可配置）key，然后淘汰最旧的key，如果淘汰后还是超过了maxmemory，就继续随机采用淘汰，直到低于maxmemory
            淘汰池：在每一次淘汰循环中，新随机出来的key列表会和淘汰池中的key列表进行融合，淘汰最旧的一个key后，保留剩余较旧的key列表放入淘汰池中留待下一个循环
            通过对象的lru值来得出空闲时间，比较空闲时间得出谁是比较旧的
            通过双向链表和hashmap实现
            还有6种淘汰算法
            
        懒惰删除
            删除指令del会直接释放对象的内存，如果删除一个元素很多的数据时，那么删除操作就会导致线程卡顿，这时就要通过懒惰删除来完成，将删除的操作交给一个异步线程来完成，主线程只是逻辑的删除。
            主线程要删除数据时，会将这个key的内存包装成一个任务，塞进异步任务队列，后台线程（LazyFreeThread）会从这个队列中取任务进行删除操作。
            对AOF文件的操作也是，每秒一次调用一次sync函数同步AOF到磁盘这个操作很耗时，redis会把这个操作交给一个独立的异步线程，这个线程的任务队列只存放AOF sync任务。
            
            
    集群的原理：分库分表，去中心化
    
        1.集群如何判断某个节点是否挂掉？
            因为集群中的每个节点都会保留其他主节点和从节点的信息，当超过一半的节点去ping某个节点没有反应时，集群认为该节点已经宕机了，然后连接它的备用节点
            
        2.集群进入fail状态的必要条件：
            某个master宕机并且没有任何从节点；
            某个master主节点和所有从节点都宕机了
            集群超过半数的主节点宕机了
            
        3.redis集群去中心化
            集群中原则每个master节点都有一个或多个salve节点。所有的master节点都可以进行读写数据，不分主次，去中心化。
            master节点和salve节点间是异步复制的，不能保证数据的强一致性。
            
        4.集群的分区规则：虚拟槽分区
            所有的键  
            
        一致性hash算法
            一致性hash算法将整个hash值空间组织成一个圆环，整个空间按顺时针方向组织，下一步将各个master进行hash，确定master在环中的位置
            来了一个key，首先计算hash值，确定此数据在环上的位置，从此位置顺时针行走，遇到第一个master就是key所在位置。一个节点挂了受影响的也只是此节点到环空间前一个节点间的数据，增节点同理。
            一致性hash算法容易造成节点分布不均匀的问题。
            引入虚拟节点可以解决这个问题，通过hash算法计算出虚拟节点的位置，把对应到虚拟节点的key再通过hash算法映射到实际的节点中
            
        hash slot算法：redis采用的方法
            主节点平分16384个槽，每个节点承担不同slot区间，将key值通过crc16算法进行hash得到一个值，再将这个值和16384进行取模得到具体槽位
            假设有ABC三个master，此时添加Dmaster，只需要将ABC的某些槽点移动到节点D即可；加如删除A，只要把A的槽点移动到其他节点即可。
              
        